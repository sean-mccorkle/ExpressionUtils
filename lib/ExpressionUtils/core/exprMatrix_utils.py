import os
import uuid
import re
import numpy
from pprint import pprint, pformat


from Workspace.WorkspaceClient import Workspace
from DataFileUtil.DataFileUtilClient import DataFileUtil
from DataFileUtil.baseclient import ServerError as DFUError
from GenomeAnnotationAPI.GenomeAnnotationAPIClient import GenomeAnnotationAPI

class ExprMatrixUtils:
    """
     Constains a set of functions for expression levels calculations.
    """

    PARAM_IN_WS_NAME = 'workspace_name'
    PARAM_IN_OBJ_NAME = 'output_obj_name'
    PARAM_IN_EXPSET_REF = 'expressionset_ref'

    def __init__(self, config, logger=None):
        self.config = config
        self.logger = logger
        self.callback_url = os.environ['SDK_CALLBACK_URL']
        self.scratch = os.path.join(config['scratch'], 'EM_' + str(uuid.uuid4()))
        self.ws_url = config['workspace-url']
        self.ws_client = Workspace(self.ws_url)
        self.dfu = DataFileUtil(self.callback_url)
        self.gaa = GenomeAnnotationAPI( self.callback_url )
        pass

    def process_params(self, params):
        """
        validates params passed to gen expression matrix method
        """
        for p in [self.PARAM_IN_EXPSET_REF,
                  self.PARAM_IN_OBJ_NAME,
                  self.PARAM_IN_WS_NAME
                 ]:
            if p not in params:
                raise ValueError('"{}" parameter is required, but missing'.format(p))

        ws_name_id = params.get(self.PARAM_IN_WS_NAME)
        if not isinstance(ws_name_id, int):
            try:
                ws_name_id = self.dfu.ws_name_to_id(ws_name_id)
            except DFUError as se:
                prefix = se.message.split('.')[0]
                raise ValueError(prefix)
        self.ws_id = ws_name_id

    def get_expressionset_data(self, expressionset_ref):

        expr_set_obj = self.ws_client.get_objects2(
            {'objects': [{'ref': expressionset_ref}]})['data'][0]

        expr_set_obj_type = expr_set_obj.get('info')[2]
        expr_set_data = dict()
        expr_set_data['ws_name'] = expr_set_obj.get('info')[7]
        expr_set_data['obj_name'] = expr_set_obj.get('info')[1]

        if re.match('KBaseRNASeq.RNASeqExpressionSet-\d.\d', expr_set_obj_type):
            expr_set_data['genome_ref'] = expr_set_obj['data']['genome_id']
            expr_obj_refs = list()
            for expr_obj in expr_set_obj['data']['mapped_expression_ids']:
                expr_obj_refs.append(expr_obj.values()[0])
            expr_set_data['expr_obj_refs'] = expr_obj_refs

        elif re.match('KBaseSets.ExpressionSet-\d.\d', expr_set_obj_type):
            items = expr_set_obj.get('data').get('items')
            expr_obj_refs = list()
            for item in items:
                expr_obj_refs.append(item['ref'])
            expr_obj = self.ws_client.get_objects2(
                {'objects': [{'ref': expr_obj_refs[0]}]})['data'][0]
            expr_set_data['genome_ref'] = expr_obj['data']['genome_id']
            expr_set_data['expr_obj_refs'] = expr_obj_refs
        else:
            raise TypeError(self.PARAM_IN_EXPSET_REF + ' should be of type ' +
                            'KBaseRNASeq.RNASeqExpressionSet ' +
                            'or KBaseSets.ExpressionSet')
        return expr_set_data

    def save_expression_matrix(self, tables, expr_set_data, em_obj_name, hidden = 0):

        all_rows = {}    # build a dictionary of keys only which is a union of all row ids (gene_ids)
        self.logger.info( '***** length of tables is {0}'.format( len( tables )))
        for table in tables:
            for r in table.keys():
                all_rows[r] = []

        for gene_id in all_rows.keys():
            row = []
            for table in tables:
                if ( gene_id in table ):
                    #logger.info( 'append ' + gene_id )
                    #logger.info( pformat( table[gene_id]))
                               #all_rows[gene_id].append( table[gene_id] )
                    row.append( table[gene_id] )
                else:
                    #logger.info( 'append  0' )
                    row.append( 0 )
                all_rows[gene_id] = row
                #logger.info( all_rows[gene_id])

        em_data = {
                    'genome_ref': expr_set_data['genome_ref'],
                    'scale': 'log2',
                    'type': 'level',
                    'data': {
                            'row_ids': [],
                            'values': [],
                            'col_ids': expr_set_data['expr_obj_names']
                            },
                    'feature_mapping' : {},
                    'condition_mapping': expr_set_data['condition_map']
                   }

        # we need to load row-by-row to preserve the order
        self.logger.info('loading expression matrix data')

        for gene_id in all_rows.keys():
            em_data['feature_mapping'][gene_id] = gene_id
            em_data['data']['row_ids'].append(gene_id)
            em_data['data']['values'].append(all_rows[gene_id])

        try:
            self.logger.info( 'saving em_data em_name {0}'.format(em_obj_name))
            obj_info = self.dfu.save_objects({'id': self.ws_id,
                                              'objects': [
                                                          { 'type': 'KBaseFeatureValues.ExpressionMatrix',
                                                            'data': em_data,
                                                            'name': em_obj_name,
                                                            'hidden': hidden,
                                                            'extra_provenance_input_refs': [
                                                                em_data.get('genome_ref'),
                                                                self.params[self.PARAM_IN_EXPSET_REF]]
                                                          }
                                                    ]})[0]
            self.logger.info('ws save return:\n' + pformat(obj_info))
        except Exception as e:
            self.logger.exception(e)
            raise Exception('Failed Saving Expression Matrix to Workspace')

        return str(obj_info[6]) + '/' + str(obj_info[0]) + '/' + str(obj_info[4])

    def get_expression_matrix(self, params):

        self.process_params(params)
        self.params = params

        expressionset_ref = params.get(self.PARAM_IN_EXPSET_REF)

        expr_set_data = self.get_expressionset_data(expressionset_ref)
        expr_obj_names = list()
        fpkm_tables = list()
        tpm_tables = list()
        condition_map = dict()
        tpm_table = None
        for expr_obj_ref in expr_set_data['expr_obj_refs']:
            try:
                self.logger.info('*** getting expression set {0} from workspace ****'
                                 .format(expr_obj_ref))

                expr = self.ws_client.get_objects2(
                                            {'objects':
                                            [{'ref': expr_obj_ref}]})['data'][0]

            except Exception, e:
                self.logger.exception(e)
                raise Exception('Unable to download expression object {0} from workspace {1}'.
                                format(expr_obj_ref, expr_set_data['ws_name']))

            expr_name = expr.get('info')[1]
            expr_obj_names.append(expr_name)
            condition_map.update({expr_name: expr.get('data').get('condition')})
            num_interp = expr.get('data').get('numerical_interpretation')
            if num_interp != 'FPKM':
                raise Exception(
                    'Did not get expected FPKM value from numerical interpretation key from \
                     Expression object {0}, instead got '.format(expr_obj_ref, num_interp))

            pr_comments = expr.get('data').get('processing_comments', None)  # log2 Normalized
            if pr_comments is not None:
                self.logger.info('pr_comments are {0}'.format(pr_comments))

            fpkm_table = expr.get('data').get('expression_levels') # QUESTION: is this really FPKM levels?
            self.logger.info('FPKM keycount: {0}'.format(len(fpkm_table.keys())))
            fpkm_tables.append(fpkm_table)

            tpm_table = None  # Cufflinks doesn't generate TPM
            if 'tpm_expression_levels' in expr['data']:  # so we need to check for this key
                tpm_table = expr.get('data').get('tpm_expression_levels')
                self.logger.info('TPM keycount: {0}'.format(len(tpm_table.keys())))
                tpm_tables.append(tpm_table)

        expr_set_data['expr_obj_names'] = expr_obj_names
        expr_set_data['condition_map'] = condition_map
        output_obj_name = params.get(self.PARAM_IN_OBJ_NAME)
        fpkm_ref = self.save_expression_matrix(fpkm_tables,
                                               expr_set_data,
                                               '{0}_FPKM_ExpressionMatrix'.format(output_obj_name))
        tpm_ref = None
        if tpm_table is not None:
            tpm_ref = self.save_expression_matrix(tpm_tables,
                                                  expr_set_data,
                                                  '{0}_TPM_ExpressionMatrix'.format(output_obj_name))
        return fpkm_ref, tpm_ref

    # returns a list of [ min, max, mean, std.dev, is_data_missing] for one row of conditional 
    # expression values

    def get_matrix_stats( self, raw_row ):

        #self.logger.info( "### gms raw row = {0}".format( pformat( raw_row ) ) )
        has_missing = "No"
        row = []
        for r in raw_row:
            if r == None or numpy.isnan( r ):     # careful here - r can be 0 which is a legitimate value
                has_missing = "Yes"
            else:
                row.append(r)

        if len( row ) < 1:
            return( [ 'NA', 'NA', 'NA', 'NA', 'Yes' ] )
        else:
            if len( row ) == 1:
               sd = 0
            else:
               sd = numpy.std( row, ddof=1 )
            return( [ min( row ), max( row ), numpy.mean( row ), sd, has_missing ] )

    # returns a dict that maps feature_id -> [ fc, q ]

    def convert_dem_to_dict( self, dem ):

        row_ids = dem.get( 'row_ids' )
        vals = dem.get( 'values' )
  
        n_rows = len( row_ids )
        if ( len( vals ) != n_rows ):
            raise Exception( "length discrepancy in differential expression matrix: {0} row_ids but {1} values".format( n_rows, len( fvals ) ) )

        dem_dict = {}
        for i in range( 0, n_rows ):
            dem_dict[ row_ids[i] ] = [ vals[i][0], vals[i][2] ] # [fc,q]. (not bothering to check for dups here)

        return dem_dict

    # implments get_enhancedFilteredExpressionMatrix() method

    def get_enhancedFEM( self, params ):

        if not params.get( 'fem_object_ref' ):
            raise ValueError( "fem_object_ref parameter not given to get_enhancedFilteredExpressionMatrix" )

        fem_object_ref = params.get( 'fem_object_ref' )

        fem_obj_ret = self.ws_client.get_objects2(
                       {'objects': [{'ref': fem_object_ref }]})['data'][0]
        fem = fem_obj_ret.get( 'data' )
        prov = fem_obj_ret.get( 'provenance')[0]

        # (1) create the enhanced FEM, starting with the FEM

        efem = {}
        for k in [ 'genome_ref', 'scale', 'type' ]:
            efem[k] = fem.get( k )

        efem['data'] = {}
        efem['data']['col_ids'] = [ "description", 
                                    "fold-change",
                                    "q-value",
                                    "min",
                                    "max",
                                    "mean",
                                    "std_dev",
                                    "is_missing_values" ]
        efem['data']['column_labels'] =[ "Description", 
                                         "Fold change",
                                         "Q value",
                                         "Min. expression",
                                         "Max. expression",
                                         "Mean expression",
                                         "Std. dev.",
                                         "Missing values?" ]
        fm = fem.get('data')
        efem['data']['row_ids'] = fm.get('row_ids')
        efem['data']['values' ] = []
        n_efem_rows = len( efem['data']['row_ids'] )
        fvals = fm.get('values')
        if ( len( fvals ) != n_efem_rows ):
            raise Exception( "length discrepancy in filtered expression matrix: {0} row_ids but {1} values".format( n_efem_rows, len( fvals ) ) )

        for i in range( 0, n_efem_rows ):
            efem['data']['values'].append( [ 'NA', 'NA', 'NA' ] + self.get_matrix_stats( fvals[i] ) )

        # (2) Get genome object and feature descriptions, put those in column 1

        feat_dict = self.gaa.get_feature_functions( { 'ref': fem.get( 'genome_ref' ), 'feature_id_list': None } )
        for i in range( 0, n_efem_rows ):
            desc = feat_dict.get( efem['data']['row_ids'][i] )
            if desc:
                efem['data']['values'][i][0] = desc     # leave as 'NA' if no entry in feat_dict

        # (3) get DEM from provenance and merge the FC and q-values

        if prov.get( 'input_ws_objects' ):
            dem_ref = prov.get( 'input_ws_objects' )[0]
            dem_obj_ret = self.ws_client.get_objects2(
                           {'objects': [{'ref': dem_ref }]})['data'][0]
            dem = dem_obj_ret.get( 'data' )
            
            dem_dict = self.convert_dem_to_dict( dem.get('data') )  # convert to dictionary for quick lookups

            for i in range( 0, n_efem_rows ):
                d = dem_dict.get( efem['data']['row_ids'][i] )
                if d:
                    efem['data']['values'][i][1], efem['data']['values'][i][2] = d

        return efem

